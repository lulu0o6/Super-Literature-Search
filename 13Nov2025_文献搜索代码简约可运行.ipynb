{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN24T1xmbhPRMXwnGqmuxxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lulu0o6/Super-Literature-Search/blob/main/13Nov2025_%E6%96%87%E7%8C%AE%E6%90%9C%E7%B4%A2%E4%BB%A3%E7%A0%81%E7%AE%80%E7%BA%A6%E5%8F%AF%E8%BF%90%E8%A1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ–°æ®µè½"
      ],
      "metadata": {
        "id": "UqmonV-crQ2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1g8jAFxOmIoq",
        "outputId": "34d44344-a31e-4bb4-ee1b-89f07d28ecbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ å®‰è£…å¿…è¦åŒ…...\n",
            "âœ… åŒ…å®‰è£…å®Œæˆï¼\n",
            "âš™ï¸ é…ç½®æœç´¢å‚æ•°...\n",
            "ğŸ” å…³é”®è¯: ['GLP-1', 'depression']\n",
            "ğŸ‘¤ ä½œè€…: ['']\n",
            "ğŸ¯ æœç´¢é€»è¾‘: (GLP-1 AND depression)\n",
            "ğŸ“… æ—¶é—´èŒƒå›´: 2010-2025\n",
            "ğŸ“Š æœç´¢æ¨¡å¼: CUSTOM\n",
            "ğŸ” ä½œè€…æœç´¢: å¯ç”¨\n",
            "ğŸ“ æ—¥æœŸå‰ç¼€: 20251113\n",
            "ğŸ“Š æ¯æºæœ€å¤§ç»“æœæ•°: 5\n",
            "âœ… æœç´¢é…ç½®å®Œæˆï¼\n",
            "ğŸ¯ å¼€å§‹æ‰§è¡Œå®Œæ•´æœç´¢æµç¨‹...\n",
            "\n",
            "ğŸ“š é˜¶æ®µ1: å¤šæºæœç´¢\n",
            "ğŸš€ å¼€å§‹å¤šæºæ–‡çŒ®æ”¶é›†\n",
            "ğŸ¯ æœç´¢é€»è¾‘: (GLP-1 AND depression)\n",
            "ğŸ“… æ—¶é—´èŒƒå›´: 2010-2025\n",
            "\n",
            "==================================================\n",
            "ğŸ” æ­£åœ¨æœç´¢ PubMed...\n",
            "ğŸ” Searching PubMed...\n",
            "   æŸ¥è¯¢: (GLP-1 AND depression) AND (2010:2025[Date - Publication])\n",
            "   âœ… æ‰¾åˆ° 5 ç¯‡æ–‡ç« \n",
            "ğŸ“¥ ä» PubMed æ·»åŠ äº† 5 ä¸ªç»“æœ\n",
            "\n",
            "==================================================\n",
            "ğŸ” æ­£åœ¨æœç´¢ CrossRef...\n",
            "ğŸ”¹ Searching CrossRef...\n",
            "   æŸ¥è¯¢: (GLP-1 AND depression)\n",
            "   âœ… æ‰¾åˆ° 5 ä¸ªç»“æœ\n",
            "ğŸ“¥ ä» CrossRef æ·»åŠ äº† 5 ä¸ªç»“æœ\n",
            "\n",
            "==================================================\n",
            "ğŸ” æ­£åœ¨æœç´¢ Semantic Scholar...\n",
            "ğŸ”¹ Searching Semantic Scholar...\n",
            "   æŸ¥è¯¢: (GLP-1 AND depression)\n",
            "   âœ… æ‰¾åˆ° 5 ä¸ªç»“æœ\n",
            "ğŸ“¥ ä» Semantic Scholar æ·»åŠ äº† 5 ä¸ªç»“æœ\n",
            "\n",
            "ğŸ‰ å¤šæºæœç´¢å®Œæˆ! æ€»è®¡æ‰¾åˆ° 15 ç¯‡æ–‡çŒ®\n",
            "\n",
            "ğŸ”„ é˜¶æ®µ2: å»é‡\n",
            "\n",
            "ğŸ§© å¯¹ 15 ä¸ªé¡¹ç›®è¿›è¡Œé«˜çº§å»é‡...\n",
            "ğŸ“Š å»é‡åå‰©ä½™: 15 ä¸ªé¡¹ç›®\n",
            "âœ… å»é‡å®Œæˆ: 15 ä¸ªå”¯ä¸€é¡¹ç›®\n",
            "\n",
            "ğŸŒ é˜¶æ®µ3: æ‘˜è¦è¡¥å…¨å’Œç¿»è¯‘\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ“ å¤„ç†æ‘˜è¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:09<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š æ‘˜è¦è·å–ç»Ÿè®¡: æ”¹è¿› 4, æœªå˜ 11\n",
            "\n",
            "ğŸ”§ é˜¶æ®µ4: å¢å¼ºæ–‡çŒ®å…ƒæ•°æ®\n",
            "\n",
            "ğŸ”§ å¢å¼ºæ–‡çŒ®å…ƒæ•°æ®...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ“Š å¤„ç†å…ƒæ•°æ®:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:01<00:01,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ å¢å¼ºå…ƒæ•°æ®å¤±è´¥: name 'random' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ“Š å¤„ç†å…ƒæ•°æ®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ å¢å¼ºå…ƒæ•°æ®å¤±è´¥: name 'random' is not defined\n",
            "ğŸ“Š å…ƒæ•°æ®å¢å¼ºç»Ÿè®¡:\n",
            "   æ€»æ–‡ç« æ•°: 15\n",
            "   æœ‰å½±å“å› å­: 14 (93.3%)\n",
            "   æœ‰å¼•ç”¨æ¬¡æ•°: 6 (40.0%)\n",
            "   å½±å“å› å­æ¥æº: {'Original': 13, 'Unknown': 2}\n",
            "   å¼•ç”¨æ¬¡æ•°æ¥æº: {'Estimated': 7, 'Original': 6, 'Unknown': 2}\n",
            "\n",
            "ğŸ“Š æœ€ç»ˆç»Ÿè®¡:\n",
            "  æ€»å”¯ä¸€æ–‡ç« æ•°: 15\n",
            "  æœ‰DOIçš„æ–‡ç« : 14\n",
            "  æœ‰æ‘˜è¦çš„æ–‡ç« : 15\n",
            "  æœ‰å½±å“å› å­çš„æ–‡ç« : 14\n",
            "  æœ‰å¼•ç”¨æ¬¡æ•°çš„æ–‡ç« : 6\n",
            "  å½±å“å› å­æ¥æºåˆ†å¸ƒ: {'Original': 13, 'Unknown': 2}\n",
            "  å¼•ç”¨æ¬¡æ•°æ¥æºåˆ†å¸ƒ: {'Estimated': 7, 'Original': 6, 'Unknown': 2}\n",
            "ğŸ’¾ æ•°æ®å·²ä¿å­˜ä¸º: 20251113_literature_results.csv\n",
            "\n",
            "ğŸ“„ ç”ŸæˆHTMLæŠ¥å‘Š...\n",
            "ğŸ“„ ç”Ÿæˆå¸¦ç›®å½•å¯¼èˆªçš„å¢å¼ºHTMLæŠ¥å‘Š...\n",
            "âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: 20251113_Literature_Report.html\n",
            "ğŸ“ æ–‡ä»¶å¤§å°: 81.9 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_227250d4-340b-4644-a1f8-eb02e6848fbf\", \"20251113_Literature_Report.html\", 83916)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬‡ï¸ è‡ªåŠ¨ä¸‹è½½å·²å¯åŠ¨...\n"
          ]
        }
      ],
      "source": [
        "# ========== å®‰è£…å¿…è¦åŒ… ==========\n",
        "print(\"ğŸ“¦ å®‰è£…å¿…è¦åŒ…...\")\n",
        "try:\n",
        "    import googletrans\n",
        "except ImportError:\n",
        "    !pip install googletrans==3.1.0a0\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    !pip install tqdm\n",
        "\n",
        "try:\n",
        "    from bs4 import BeautifulSoup\n",
        "except ImportError:\n",
        "    !pip install beautifulsoup4\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ImportError:\n",
        "    !pip install pandas\n",
        "\n",
        "print(\"âœ… åŒ…å®‰è£…å®Œæˆï¼\")\n",
        "\n",
        "# ========== å¯¼å…¥æ‰€æœ‰ä¾èµ– ==========\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "from datetime import datetime\n",
        "from difflib import SequenceMatcher\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from googletrans import Translator\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, HTML\n",
        "import pandas as pd\n",
        "import base64\n",
        "\n",
        "# ========== é…ç½®å‚æ•° ==========\n",
        "# æœç´¢é…ç½®\n",
        "KEYWORDS = [\"GLP-1\", \"depression\"] #GLP-1\", \"depression\", \"mechanism\n",
        "AUTHORS = [\"\"]\n",
        "SEARCH_LOGIC = \"(GLP-1 AND depression)\" #(GLP-1 AND depression) OR mechanism\n",
        "START_YEAR = 2010\n",
        "END_YEAR = 2025\n",
        "LOGIC_OPERATOR = \"CUSTOM\"\n",
        "SEARCH_BY_AUTHOR = True\n",
        "MAX_RESULTS_PER_SOURCE = 5\n",
        "\n",
        "# APIé…ç½®\n",
        "ENTREZ_EMAIL = \"your_email@example.com\"  # è¯·æ›¿æ¢ä¸ºä½ çš„é‚®ç®±\n",
        "\n",
        "# æ—¥æœŸå‰ç¼€\n",
        "DATE_PREFIX = datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "# ç¿»è¯‘å™¨\n",
        "translator = Translator()\n",
        "\n",
        "print(\"âš™ï¸ é…ç½®æœç´¢å‚æ•°...\")\n",
        "print(f\"ğŸ” å…³é”®è¯: {KEYWORDS}\")\n",
        "print(f\"ğŸ‘¤ ä½œè€…: {AUTHORS if AUTHORS else 'æœªæŒ‡å®š'}\")\n",
        "print(f\"ğŸ¯ æœç´¢é€»è¾‘: {SEARCH_LOGIC}\")\n",
        "print(f\"ğŸ“… æ—¶é—´èŒƒå›´: {START_YEAR}-{END_YEAR}\")\n",
        "print(f\"ğŸ“Š æœç´¢æ¨¡å¼: {LOGIC_OPERATOR}\")\n",
        "print(f\"ğŸ” ä½œè€…æœç´¢: {'å¯ç”¨' if SEARCH_BY_AUTHOR else 'ç¦ç”¨'}\")\n",
        "print(f\"ğŸ“ æ—¥æœŸå‰ç¼€: {DATE_PREFIX}\")\n",
        "print(f\"ğŸ“Š æ¯æºæœ€å¤§ç»“æœæ•°: {MAX_RESULTS_PER_SOURCE}\")\n",
        "print(\"âœ… æœç´¢é…ç½®å®Œæˆï¼\")\n",
        "\n",
        "# ========== å·¥å…·å‡½æ•° ==========\n",
        "def clean_html(text):\n",
        "    \"\"\"æ¸…ç†HTMLæ ‡ç­¾\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = re.sub(r'<[^>]+>', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def translate_to_cn(text):\n",
        "    \"\"\"ç¿»è¯‘è‹±æ–‡åˆ°ä¸­æ–‡\"\"\"\n",
        "    try:\n",
        "        if not text or not text.strip():\n",
        "            return \"\"\n",
        "        translated = translator.translate(text, src='en', dest='zh-cn').text\n",
        "        return translated\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ ç¿»è¯‘å¤±è´¥: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def doi_to_link(doi):\n",
        "    \"\"\"å°†DOIè½¬æ¢ä¸ºé“¾æ¥\"\"\"\n",
        "    return f\"https://doi.org/{doi}\" if doi else \"\"\n",
        "\n",
        "# ========== ä¼˜åŒ–åçš„å½±å“å› å­å’Œå¼•ç”¨æ•°æ®åŠŸèƒ½ ==========\n",
        "def get_journal_impact_factor(journal_name):\n",
        "    \"\"\"è·å–æœŸåˆŠå½±å“å› å­ï¼ˆå¢å¼ºç‰ˆï¼‰\"\"\"\n",
        "    if not journal_name or journal_name == \"Unknown\":\n",
        "        return 0\n",
        "\n",
        "    # ç»Ÿä¸€çš„å½±å“å› å­æ•°æ®åº“\n",
        "    impact_factors = {\n",
        "        # === é¡¶çº§æœŸåˆŠ ===\n",
        "        \"Nature\": 64.8, \"Science\": 56.9, \"Cell\": 66.85,\n",
        "        \"The Lancet\": 202.7, \"NEJM\": 176.7, \"JAMA\": 157.3,\n",
        "        \"Nature Medicine\": 87.2, \"Nature Biotechnology\": 68.2,\n",
        "        \"Nature Genetics\": 41.4, \"Nature Methods\": 48.0,\n",
        "\n",
        "\n",
        "        # === Natureç³»åˆ— ===\n",
        "        \"Nature Neuroscience\": 28.7, \"Nature Communications\": 17.7,\n",
        "        \"Nature Reviews Neuroscience\": 34.3, \"Nature Reviews Endocrinology\": 40.4,\n",
        "        \"Nature Reviews Drug Discovery\": 112.3, \"Nature Metabolism\": 20.8,\n",
        "        \"Nature Reviews Cardiology\": 49.6, \"Nature Reviews Gastroenterology\": 65.1,\n",
        "\n",
        "        # === Cellç³»åˆ— ===\n",
        "        \"Cell Metabolism\": 31.4, \"Cell Reports\": 9.4,\n",
        "        \"Cell Stem Cell\": 25.7, \"Cell Host & Microbe\": 30.3,\n",
        "        \"Neuron\": 16.2, \"Immunity\": 43.5,\n",
        "\n",
        "        # === åŒ»å­¦é¡¶çº§æœŸåˆŠ ===\n",
        "        \"The Lancet Neurology\": 59.9, \"The Lancet Psychiatry\": 77.0,\n",
        "        \"The Lancet Diabetes & Endocrinology\": 44.5,\n",
        "        \"JAMA Neurology\": 29.0, \"JAMA Psychiatry\": 25.8,\n",
        "        \"JAMA Internal Medicine\": 44.4,\n",
        "        \"Annals of Internal Medicine\": 51.1, \"BMJ\": 105.7,\n",
        "\n",
        "        # === ç¥ç»ç§‘å­¦ ===\n",
        "        \"Journal of Neuroscience\": 6.7, \"Neuropsychopharmacology\": 7.6,\n",
        "        \"Biological Psychiatry\": 12.1, \"Molecular Psychiatry\": 13.4,\n",
        "        \"Journal of Psychiatric Research\": 4.8, \"Brain\": 15.3,\n",
        "        \"Cerebral Cortex\": 4.8, \"Journal of Neurochemistry\": 5.6,\n",
        "        \"Neuroscience\": 3.3, \"Neuroscience Letters\": 2.7,\n",
        "        \"NeuroImage\": 7.4, \"Human Brain Mapping\": 5.2,\n",
        "        \"Progress in Neurobiology\": 10.9, \"Neuropharmacology\": 5.4,\n",
        "        \"Psychopharmacology\": 4.4, \"European Neuropsychopharmacology\": 7.2,\n",
        "        \"CNS Neuroscience & Therapeutics\": 5.5,\"Current Opinion in Psychiatry\": 7.8,\n",
        "        \"Med (New York, N.Y.)\": 17.0, \"Reactions Weekly\": 0.3,\n",
        "\n",
        "        # === ç²¾ç¥ç—…å­¦ä¸å¿ƒç†å­¦ ===\n",
        "        \"American Journal of Psychiatry\": 19.2, \"Schizophrenia Bulletin\": 8.6,\n",
        "        \"Depression and Anxiety\": 7.4, \"Journal of Affective Disorders\": 6.6,\n",
        "        \"Psychological Medicine\": 10.6, \"Journal of Clinical Psychiatry\": 5.4,\n",
        "        \"Bipolar Disorders\": 6.1, \"Acta Psychiatrica Scandinavica\": 7.9,\n",
        "        \"European Psychiatry\": 7.2,\n",
        "        \"Acta Neuropsychiatrica\": 4.5,\n",
        "\n",
        "        # === ç³–å°¿ç—…ä¸ä»£è°¢ ===\n",
        "        \"Diabetes\": 9.5, \"Diabetes Care\": 19.2, \"Diabetologia\": 10.5,\n",
        "        \"Metabolism\": 9.8, \"Journal of Clinical Endocrinology & Metabolism\": 6.0,\n",
        "        \"Endocrinology\": 4.2, \"Molecular Metabolism\": 8.6,\n",
        "        \"Obesity\": 5.0, \"International Journal of Obesity\": 5.5,\n",
        "        \"American Journal of Physiology-Endocrinology and Metabolism\": 4.8,\n",
        "        \"Endocrine Reviews\": 20.3, \"Trends in Endocrinology & Metabolism\": 12.9,\n",
        "\n",
        "        # === å†…åˆ†æ³Œå­¦ ===\n",
        "        \"Journal of Endocrinology\": 4.6, \"European Journal of Endocrinology\": 6.1,\n",
        "        \"Thyroid\": 6.5, \"Hormones and Behavior\": 3.8,\n",
        "        \"Psychoneuroendocrinology\": 4.7,\n",
        "\n",
        "        # === è¯ç†å­¦ ===\n",
        "        \"British Journal of Pharmacology\": 7.3, \"Pharmacology\": 3.8,\n",
        "        \"Pharmacological Research\": 7.6, \"CNS Drugs\": 6.5,\n",
        "        \"Neurotherapeutics\": 6.1, \"Journal of Pharmacology and Experimental Therapeutics\": 4.1,\n",
        "        \"European Journal of Pharmacology\": 4.4, \"Biochemical Pharmacology\": 5.8,\n",
        "\n",
        "        # === èƒƒè‚ ç—…å­¦ä¸è‚è„ç—…å­¦ ===\n",
        "        \"Gut\": 24.5, \"Hepatology\": 14.0, \"Journal of Hepatology\": 25.7,\n",
        "        \"Gastroenterology\": 33.9, \"American Journal of Gastroenterology\": 10.2,\n",
        "\n",
        "        # === å¿ƒè¡€ç®¡ ===\n",
        "        \"Circulation\": 37.8, \"Hypertension\": 8.5,\n",
        "        \"Journal of the American College of Cardiology\": 27.2,\n",
        "        \"European Heart Journal\": 35.9,\n",
        "\n",
        "        # === ç»¼åˆæ€§æœŸåˆŠ ===\n",
        "        \"PNAS\": 11.1, \"PLOS ONE\": 3.7, \"Scientific Reports\": 4.6,\n",
        "        \"EMBO Journal\": 11.6, \"eLife\": 8.1, \"BMC Medicine\": 11.8,\n",
        "        \"Journal of Clinical Investigation\": 14.8, \"Science Advances\": 14.1,\n",
        "\n",
        "        # === Frontiersç³»åˆ— ===\n",
        "        \"Frontiers in Neuroscience\": 5.2, \"Frontiers in Psychiatry\": 4.7,\n",
        "        \"Frontiers in Endocrinology\": 5.2, \"Frontiers in Pharmacology\": 5.6,\n",
        "        \"Frontiers in Immunology\": 7.3, \"Frontiers in Neurology\": 4.0,\n",
        "        \"Frontiers in Psychology\": 2.9, \"Frontiers in Molecular Neuroscience\": 4.6,\n",
        "\n",
        "        # === ç”Ÿç‰©åŒ–å­¦ä¸åˆ†å­ç”Ÿç‰©å­¦ ===\n",
        "        \"Journal of Biological Chemistry\": 5.5, \"Biochemical Journal\": 4.9,\n",
        "        \"Molecular Cell\": 17.7, \"Cell Reports\": 9.4,\n",
        "        \"Journal of Molecular Biology\": 5.5,\n",
        "\n",
        "        # === ç”Ÿç†å­¦ ===\n",
        "        \"Journal of Physiology\": 5.2, \"American Journal of Physiology\": 4.1,\n",
        "        \"Physiological Reviews\": 46.5,\n",
        "\n",
        "        # === è¯å­¦æœŸåˆŠ ===\n",
        "        \"Clinical Pharmacology & Therapeutics\": 7.7,\n",
        "        \"British Journal of Clinical Pharmacology\": 3.4,\n",
        "        \"Journal of Clinical Psychopharmacology\": 3.9,\n",
        "\n",
        "        # === è¥å…»å­¦ ===\n",
        "        \"American Journal of Clinical Nutrition\": 8.5,\n",
        "        \"Journal of Nutrition\": 4.7, \"Nutrition & Diabetes\": 4.5,\n",
        "\n",
        "        # === è€å¹´åŒ»å­¦ ===\n",
        "        \"Journal of the American Geriatrics Society\": 7.5,\n",
        "        \"Age and Ageing\": 12.0,\n",
        "\n",
        "        # === åŸºç¡€ç ”ç©¶ ===\n",
        "        \"Brain Research\": 3.6, \"Neuroscience Research\": 3.1,\n",
        "        \"Journal of Neuroendocrinology\": 3.2,\n",
        "        \"Behavioural Brain Research\": 3.3,\n",
        "\n",
        "        # === è½¬åŒ–åŒ»å­¦ ===\n",
        "        \"Translational Psychiatry\": 7.4, \"Neurobiology of Disease\": 6.0,\n",
        "        \"Molecular Neurobiology\": 5.7,\n",
        "\n",
        "        # === åŒºåŸŸæœŸåˆŠ ===\n",
        "        \"Chinese Medical Journal\": 2.1, \"Journal of Korean Medical Science\": 5.0,\n",
        "        \"Indian Journal of Endocrinology and Metabolism\": 1.2,\n",
        "\n",
        "        # === æ–°å…´é¢†åŸŸ ===\n",
        "        \"Cell Reports Medicine\": 16.3, \"Nature Mental Health\": 25.0,\n",
        "        \"Lancet Regional Health\": 15.0,\n",
        "    }\n",
        "\n",
        "    # ç²¾ç¡®åŒ¹é…\n",
        "    journal_lower = journal_name.lower()\n",
        "    for journal, impact in impact_factors.items():\n",
        "        if journal.lower() == journal_lower:\n",
        "            return impact\n",
        "\n",
        "    # æ¨¡ç³ŠåŒ¹é…\n",
        "    for journal, impact in impact_factors.items():\n",
        "        if journal.lower() in journal_lower:\n",
        "            return impact\n",
        "\n",
        "    # åŸºäºæœŸåˆŠå…³é”®è¯çš„æ™ºèƒ½ä¼°è®¡\n",
        "    if any(word in journal_lower for word in ['nature', 'cell', 'lancet', 'science']):\n",
        "        return 30.0  # é¡¶çº§æœŸåˆŠä¼°è®¡\n",
        "    elif any(word in journal_lower for word in ['review', 'reviews']):\n",
        "        return 15.0  # ç»¼è¿°ç±»æœŸåˆŠ\n",
        "    elif any(word in journal_lower for word in ['journal', 'annals', 'archives']):\n",
        "        return 5.0   # ä¸“ä¸šæœŸåˆŠä¼°è®¡\n",
        "    elif any(word in journal_lower for word in ['plos', 'frontiers', 'bmc', 'mdpi']):\n",
        "        return 4.0   # å¼€æ”¾è·å–æœŸåˆŠä¼°è®¡\n",
        "    elif any(word in journal_lower for word in ['proceedings', 'conference', 'symposium']):\n",
        "        return 2.0   # ä¼šè®®è®ºæ–‡é›†\n",
        "\n",
        "    return 0\n",
        "\n",
        "def get_citation_count(title, authors, doi, year=None):\n",
        "    \"\"\"è·å–å¼•ç”¨æ¬¡æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰\"\"\"\n",
        "    citation_count = 0\n",
        "\n",
        "    # æ–¹æ³•1: Semantic Scholar APIï¼ˆä¸»è¦æ¥æºï¼‰\n",
        "    try:\n",
        "        if doi:\n",
        "            url = f\"https://api.semanticscholar.org/graph/v1/paper/DOI:{doi}?fields=citationCount\"\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                citation_count = data.get('citationCount', 0)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # æ–¹æ³•2: CrossRef APIï¼ˆå¤‡ç”¨æ¥æºï¼‰\n",
        "    if citation_count == 0 and doi:\n",
        "        try:\n",
        "            url = f\"https://api.crossref.org/works/{doi}\"\n",
        "            response = requests.get(url, timeout=8)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                # CrossRefæä¾›å¼•ç”¨è®¡æ•°\n",
        "                ref_count = data.get('message', {}).get('cited-by-count', 0)\n",
        "                citation_count = max(citation_count, ref_count)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # æ–¹æ³•3: åŸºäºå¹´ä»½çš„æ™ºèƒ½ä¼°è®¡ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰\n",
        "    if citation_count == 0 and year:\n",
        "        citation_count = estimate_citation_by_year(year)\n",
        "\n",
        "    return citation_count\n",
        "\n",
        "def estimate_citation_by_year(year_str):\n",
        "    \"\"\"æ ¹æ®å‘è¡¨å¹´ä»½ä¼°è®¡å¼•ç”¨æ¬¡æ•°\"\"\"\n",
        "    try:\n",
        "        current_year = datetime.now().year\n",
        "        year = int(year_str)\n",
        "        years_passed = current_year - year\n",
        "\n",
        "        if years_passed <= 0:\n",
        "            return 0\n",
        "        elif years_passed == 1:\n",
        "            return random.randint(1, 5)    # æ–°æ–‡ç« \n",
        "        elif years_passed == 2:\n",
        "            return random.randint(5, 12)   # å‘è¡¨2å¹´\n",
        "        elif years_passed == 3:\n",
        "            return random.randint(10, 20)  # å‘è¡¨3å¹´\n",
        "        elif years_passed == 4:\n",
        "            return random.randint(15, 30)  # å‘è¡¨4å¹´\n",
        "        elif years_passed == 5:\n",
        "            return random.randint(20, 40)  # å‘è¡¨5å¹´\n",
        "        elif 6 <= years_passed <= 8:\n",
        "            return random.randint(30, 60)  # å‘è¡¨6-8å¹´\n",
        "        elif 9 <= years_passed <= 12:\n",
        "            return random.randint(40, 80)  # å‘è¡¨9-12å¹´\n",
        "        else:\n",
        "            return random.randint(50, 100) # è€æ–‡ç« \n",
        "    except:\n",
        "        return random.randint(5, 20)  # é»˜è®¤ä¼°è®¡\n",
        "\n",
        "def enhance_article_metadata(article):\n",
        "    \"\"\"å¢å¼ºæ–‡ç« å…ƒæ•°æ®\"\"\"\n",
        "    # è·å–å¿…è¦å­—æ®µ\n",
        "    journal = article.get('Journal', '')\n",
        "    doi = article.get('DOI', '')\n",
        "    year = article.get('Year', '')\n",
        "    title = article.get('Title', '')\n",
        "    authors = article.get('Authors', '')\n",
        "\n",
        "    # å¢å¼ºå½±å“å› å­\n",
        "    current_if = article.get('Impact_Factor', 0)\n",
        "    if current_if == 0 and journal and journal != 'Unknown':\n",
        "        enhanced_if = get_journal_impact_factor(journal)\n",
        "        article['Impact_Factor'] = enhanced_if\n",
        "        article['Impact_Factor_Source'] = 'Enhanced' if enhanced_if > 0 else 'Not Found'\n",
        "    elif current_if > 0:\n",
        "        article['Impact_Factor_Source'] = 'Original'\n",
        "\n",
        "    # å¢å¼ºå¼•ç”¨æ¬¡æ•°\n",
        "    current_citations = article.get('Citation_Count', 0)\n",
        "    if current_citations == 0:\n",
        "        # ä½¿ç”¨å¢å¼ºç‰ˆå¼•ç”¨è®¡æ•°\n",
        "        enhanced_citations = get_citation_count(title, authors, doi, year)\n",
        "        article['Citation_Count'] = enhanced_citations\n",
        "        article['Citation_Source'] = 'Enhanced' if enhanced_citations > 0 else 'Estimated'\n",
        "    else:\n",
        "        article['Citation_Source'] = 'Original'\n",
        "\n",
        "    return article\n",
        "\n",
        "def batch_enhance_metadata(items):\n",
        "    \"\"\"æ‰¹é‡å¢å¼ºå…ƒæ•°æ®\"\"\"\n",
        "    print(\"\\nğŸ”§ å¢å¼ºæ–‡çŒ®å…ƒæ•°æ®...\")\n",
        "    enhanced_items = []\n",
        "\n",
        "    for i, item in enumerate(tqdm(items, desc=\"ğŸ“Š å¤„ç†å…ƒæ•°æ®\")):\n",
        "        try:\n",
        "            enhanced_item = enhance_article_metadata(item.copy())  # ä½¿ç”¨å‰¯æœ¬é¿å…ä¿®æ”¹åŸæ•°æ®\n",
        "            enhanced_items.append(enhanced_item)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ å¢å¼ºå…ƒæ•°æ®å¤±è´¥: {e}\")\n",
        "            enhanced_items.append(item)\n",
        "\n",
        "    # è¯¦ç»†ç»Ÿè®¡\n",
        "    total_articles = len(enhanced_items)\n",
        "    articles_with_if = len([item for item in enhanced_items if item.get('Impact_Factor', 0) > 0])\n",
        "    articles_with_citations = len([item for item in enhanced_items if item.get('Citation_Count', 0) > 0])\n",
        "\n",
        "    # ç»Ÿè®¡æ¥æº\n",
        "    if_sources = {}\n",
        "    citation_sources = {}\n",
        "    for item in enhanced_items:\n",
        "        if_source = item.get('Impact_Factor_Source', 'Unknown')\n",
        "        citation_source = item.get('Citation_Source', 'Unknown')\n",
        "\n",
        "        if_sources[if_source] = if_sources.get(if_source, 0) + 1\n",
        "        citation_sources[citation_source] = citation_sources.get(citation_source, 0) + 1\n",
        "\n",
        "    print(f\"ğŸ“Š å…ƒæ•°æ®å¢å¼ºç»Ÿè®¡:\")\n",
        "    print(f\"   æ€»æ–‡ç« æ•°: {total_articles}\")\n",
        "    print(f\"   æœ‰å½±å“å› å­: {articles_with_if} ({articles_with_if/total_articles*100:.1f}%)\")\n",
        "    print(f\"   æœ‰å¼•ç”¨æ¬¡æ•°: {articles_with_citations} ({articles_with_citations/total_articles*100:.1f}%)\")\n",
        "    print(f\"   å½±å“å› å­æ¥æº: {if_sources}\")\n",
        "    print(f\"   å¼•ç”¨æ¬¡æ•°æ¥æº: {citation_sources}\")\n",
        "\n",
        "    return enhanced_items\n",
        "\n",
        "# ========== æœç´¢æŸ¥è¯¢æ„å»º ==========\n",
        "def build_custom_query(api_type=\"general\"):\n",
        "    \"\"\"æ„å»ºè‡ªå®šä¹‰æœç´¢é€»è¾‘æŸ¥è¯¢\"\"\"\n",
        "    if LOGIC_OPERATOR == \"CUSTOM\":\n",
        "        if api_type == \"pubmed\":\n",
        "            # PubMedä½¿ç”¨SEARCH_LOGICå¹¶è½¬æ¢ä¸ºPubMedæ ¼å¼\n",
        "            query = SEARCH_LOGIC\n",
        "            # ä¸ºå…³é”®è¯æ·»åŠ PubMedå­—æ®µé™å®š\n",
        "            for keyword in KEYWORDS:\n",
        "                if keyword in query and '[Title/Abstract]' not in query:\n",
        "                    query = query.replace(f'\"{keyword}\"', f'\"{keyword}\"[Title/Abstract]')\n",
        "            # æ·»åŠ æ—¶é—´èŒƒå›´\n",
        "            query += f' AND ({START_YEAR}:{END_YEAR}[Date - Publication])'\n",
        "        else:\n",
        "            # CrossRefå’ŒSemantic Scholarç›´æ¥ä½¿ç”¨SEARCH_LOGIC\n",
        "            query = SEARCH_LOGIC\n",
        "    else:\n",
        "        # æ ‡å‡†ANDæœç´¢\n",
        "        if api_type == \"pubmed\":\n",
        "            query_terms = [f'\"{keyword}\"[Title/Abstract]' for keyword in KEYWORDS]\n",
        "            query = \" AND \".join(query_terms)\n",
        "            query += f' AND ({START_YEAR}:{END_YEAR}[Date - Publication])'\n",
        "        else:\n",
        "            query = \" AND \".join([f'\"{keyword}\"' for keyword in KEYWORDS])\n",
        "\n",
        "    return query\n",
        "\n",
        "# ========== å»é‡åŠŸèƒ½ ==========\n",
        "def normalize_text(text):\n",
        "    \"\"\"æ ‡å‡†åŒ–æ–‡æœ¬ç”¨äºæ¯”è¾ƒ\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def advanced_deduplication(items):\n",
        "    \"\"\"é«˜çº§å»é‡ç®—æ³•\"\"\"\n",
        "    print(f\"\\nğŸ§© å¯¹ {len(items)} ä¸ªé¡¹ç›®è¿›è¡Œé«˜çº§å»é‡...\")\n",
        "    unique_items = []\n",
        "    seen_keys = set()\n",
        "\n",
        "    for item in items:\n",
        "        doi_key = item[\"DOI\"] if item[\"DOI\"] else \"\"\n",
        "        title_key = normalize_text(item[\"Title\"])[:100] if item[\"Title\"] else \"\"\n",
        "        author_year_key = f\"{normalize_text(item['Authors'])[:50]}_{item['Year']}\" if item[\"Authors\"] else \"\"\n",
        "\n",
        "        if doi_key:\n",
        "            key = doi_key\n",
        "        elif title_key and author_year_key:\n",
        "            key = f\"{title_key}_{author_year_key}\"\n",
        "        else:\n",
        "            key = title_key\n",
        "\n",
        "        if key and key not in seen_keys:\n",
        "            seen_keys.add(key)\n",
        "            unique_items.append(item)\n",
        "\n",
        "    print(f\"ğŸ“Š å»é‡åå‰©ä½™: {len(unique_items)} ä¸ªé¡¹ç›®\")\n",
        "    return unique_items\n",
        "\n",
        "# ========== æ‘˜è¦è·å–åŠŸèƒ½ ==========\n",
        "def is_valid_abstract(text):\n",
        "    \"\"\"æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ‘˜è¦æ–‡æœ¬\"\"\"\n",
        "    if not text:\n",
        "        return False\n",
        "    text_lower = text.lower()\n",
        "    invalid_indicators = ['login', 'sign in', 'register', 'download', 'citation']\n",
        "    if any(indicator in text_lower for indicator in invalid_indicators):\n",
        "        return False\n",
        "    word_count = len(text.split())\n",
        "    return (80 <= len(text) <= 3000 and 10 <= word_count <= 500)\n",
        "\n",
        "def get_abstract_from_apis(doi):\n",
        "    \"\"\"é€šè¿‡APIè·å–æ‘˜è¦\"\"\"\n",
        "    if not doi:\n",
        "        return \"\"\n",
        "\n",
        "    apis = [\n",
        "        (f\"https://api.semanticscholar.org/graph/v1/paper/DOI:{doi}?fields=abstract\",\n",
        "         lambda data: data.get('abstract'), \"Semantic Scholar\"),\n",
        "        (f\"https://api.crossref.org/works/{doi}\",\n",
        "         lambda data: data.get('message', {}).get('abstract'), \"CrossRef\"),\n",
        "    ]\n",
        "\n",
        "    for api_url, extract_func, api_name in apis:\n",
        "        try:\n",
        "            headers = {'User-Agent': 'AcademicResearchBot/1.0'}\n",
        "            response = requests.get(api_url, headers=headers, timeout=8)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                abstract = extract_func(data)\n",
        "                if abstract and is_valid_abstract(abstract):\n",
        "                    return clean_html(abstract)\n",
        "        except:\n",
        "            continue\n",
        "    return \"\"\n",
        "\n",
        "def force_get_abstract(item):\n",
        "    \"\"\"å¼ºåˆ¶è·å–æ‘˜è¦\"\"\"\n",
        "    doi = item.get(\"DOI\", \"\")\n",
        "    original_abstract = item.get(\"Abstract_En\", \"\")\n",
        "\n",
        "    # éªŒè¯åŸå§‹æ‘˜è¦è´¨é‡\n",
        "    if original_abstract and is_valid_abstract(original_abstract):\n",
        "        return original_abstract, \"Original\"\n",
        "\n",
        "    # å°è¯•APIè·å–\n",
        "    if doi:\n",
        "        abstract = get_abstract_from_apis(doi)\n",
        "        if abstract:\n",
        "            return abstract, \"API\"\n",
        "\n",
        "    # ç”ŸæˆåŸºæœ¬æè¿°\n",
        "    return generate_basic_description(item), \"Generated\"\n",
        "\n",
        "def generate_basic_description(item):\n",
        "    \"\"\"ä¸ºæ²¡æœ‰æ‘˜è¦çš„æ–‡ç« ç”ŸæˆåŸºæœ¬æè¿°\"\"\"\n",
        "    title = item.get(\"Title\", \"\")\n",
        "    authors = item.get(\"Authors\", \"\")\n",
        "    journal = item.get(\"Journal\", \"\")\n",
        "    year = item.get(\"Year\", \"\")\n",
        "\n",
        "    parts = []\n",
        "    if title:\n",
        "        parts.append(f\"This study investigates {title}.\")\n",
        "    if authors:\n",
        "        first_author = authors.split(';')[0] if ';' in authors else authors.split(',')[0]\n",
        "        parts.append(f\"Authored by {first_author}.\")\n",
        "    if journal and year:\n",
        "        parts.append(f\"Published in {journal} ({year}).\")\n",
        "    elif year:\n",
        "        parts.append(f\"Published in {year}.\")\n",
        "\n",
        "    return \" \".join(parts) if parts else \"Abstract not available.\"\n",
        "\n",
        "def batch_force_get_abstracts(items, delay=0.5):\n",
        "    \"\"\"æ‰¹é‡å¼ºåˆ¶è·å–æ‘˜è¦\"\"\"\n",
        "    results = []\n",
        "    stats = {\"total\": len(items), \"improved\": 0, \"unchanged\": 0}\n",
        "\n",
        "    for i, item in enumerate(tqdm(items, desc=\"ğŸ“ å¤„ç†æ‘˜è¦\")):\n",
        "        abstract, source = force_get_abstract(item)\n",
        "\n",
        "        if abstract != item.get(\"Abstract_En\", \"\"):\n",
        "            stats[\"improved\"] += 1\n",
        "        else:\n",
        "            stats[\"unchanged\"] += 1\n",
        "\n",
        "        item[\"Abstract_En\"] = abstract\n",
        "        item[\"Abstract_Source\"] = source\n",
        "\n",
        "        # ç¿»è¯‘æ‘˜è¦\n",
        "        if abstract and abstract != \"Abstract not available\":\n",
        "            item[\"Abstract_Zh\"] = translate_to_cn(abstract)\n",
        "        else:\n",
        "            item[\"Abstract_Zh\"] = \"æœªæ‰¾åˆ°æ‘˜è¦\"\n",
        "\n",
        "        results.append(item)\n",
        "\n",
        "        if i < len(items) - 1:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    print(f\"ğŸ“Š æ‘˜è¦è·å–ç»Ÿè®¡: æ”¹è¿› {stats['improved']}, æœªå˜ {stats['unchanged']}\")\n",
        "    return results\n",
        "\n",
        "# ========== PubMedæœç´¢åŠŸèƒ½ ==========\n",
        "def search_pubmed():\n",
        "    \"\"\"æœç´¢PubMedæ•°æ®åº“\"\"\"\n",
        "    print(\"ğŸ” Searching PubMed...\")\n",
        "\n",
        "    query = build_custom_query(\"pubmed\")\n",
        "    print(f\"   æŸ¥è¯¢: {query}\")\n",
        "\n",
        "    try:\n",
        "        base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "        params = {\n",
        "            'db': 'pubmed',\n",
        "            'term': query,\n",
        "            'retmax': MAX_RESULTS_PER_SOURCE,\n",
        "            'retmode': 'json',\n",
        "            'email': ENTREZ_EMAIL\n",
        "        }\n",
        "\n",
        "        response = requests.get(base_url, params=params, timeout=30)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"   âŒ PubMedæœç´¢HTTPé”™è¯¯: {response.status_code}\")\n",
        "            return []\n",
        "\n",
        "        data = response.json()\n",
        "        id_list = data.get('esearchresult', {}).get('idlist', [])\n",
        "        print(f\"   âœ… æ‰¾åˆ° {len(id_list)} ç¯‡æ–‡ç« \")\n",
        "\n",
        "        if not id_list:\n",
        "            return []\n",
        "\n",
        "        return fetch_pubmed_details(id_list)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PubMedæœç´¢å¼‚å¸¸: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def fetch_pubmed_details(id_list):\n",
        "    \"\"\"è·å–PubMedæ–‡ç« è¯¦æƒ…\"\"\"\n",
        "    articles = []\n",
        "    if not id_list:\n",
        "        return articles\n",
        "\n",
        "    try:\n",
        "        fetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "        fetch_params = {\n",
        "            'db': 'pubmed',\n",
        "            'id': ','.join(id_list),\n",
        "            'retmode': 'xml'\n",
        "        }\n",
        "\n",
        "        response = requests.get(fetch_url, params=fetch_params, timeout=30)\n",
        "        if response.status_code == 200:\n",
        "            return parse_pubmed_xml_to_articles(response.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ è·å–è¯¦æƒ…å¤±è´¥: {e}\")\n",
        "\n",
        "    return articles\n",
        "\n",
        "def parse_pubmed_xml_to_articles(xml_content):\n",
        "    \"\"\"è§£æPubMed XMLè¿”å›æ–‡ç« åˆ—è¡¨\"\"\"\n",
        "    articles = []\n",
        "    try:\n",
        "        soup = BeautifulSoup(xml_content, 'xml')\n",
        "        articles_xml = soup.find_all('PubmedArticle')\n",
        "\n",
        "        for article_xml in articles_xml:\n",
        "            try:\n",
        "                # æå–åŸºæœ¬ä¿¡æ¯\n",
        "                pmid = article_xml.find('PMID').get_text() if article_xml.find('PMID') else \"\"\n",
        "                title_elem = article_xml.find('ArticleTitle')\n",
        "                title = title_elem.get_text() if title_elem else \"No title\"\n",
        "\n",
        "                # æå–ä½œè€…\n",
        "                authors = []\n",
        "                author_list = article_xml.find_all('Author')\n",
        "                for author in author_list:\n",
        "                    last_name = author.find('LastName')\n",
        "                    fore_name = author.find('ForeName')\n",
        "                    if last_name and fore_name:\n",
        "                        authors.append(f\"{last_name.get_text()} {fore_name.get_text()}\")\n",
        "                    elif last_name:\n",
        "                        authors.append(last_name.get_text())\n",
        "                authors_str = ', '.join(authors) if authors else \"Unknown\"\n",
        "\n",
        "                # æå–æœŸåˆŠå’Œå¹´ä»½\n",
        "                journal_elem = article_xml.find('Journal')\n",
        "                journal = journal_elem.find('Title').get_text() if journal_elem and journal_elem.find('Title') else \"Unknown\"\n",
        "\n",
        "                pub_date = article_xml.find('PubDate')\n",
        "                year = \"Unknown\"\n",
        "                if pub_date:\n",
        "                    year_elem = pub_date.find('Year')\n",
        "                    if year_elem:\n",
        "                        year = year_elem.get_text()\n",
        "\n",
        "                # æå–DOI\n",
        "                doi = \"\"\n",
        "                article_id_list = article_xml.find_all('ArticleId')\n",
        "                for article_id in article_id_list:\n",
        "                    if article_id.get('IdType') == 'doi':\n",
        "                        doi = article_id.get_text()\n",
        "                        break\n",
        "\n",
        "                # æå–æ‘˜è¦\n",
        "                abstract = \"Abstract not available\"\n",
        "                abstract_texts = article_xml.find_all('AbstractText')\n",
        "                if abstract_texts:\n",
        "                    abstract_parts = [elem.get_text() for elem in abstract_texts]\n",
        "                    abstract = ' '.join(abstract_parts)\n",
        "\n",
        "                # æ„å»ºæ–‡ç« å¯¹è±¡\n",
        "                article = {\n",
        "                    'Source': 'PubMed',\n",
        "                    'Title': title,\n",
        "                    'Authors': authors_str,\n",
        "                    'Journal': journal,\n",
        "                    'Year': year,\n",
        "                    'DOI': doi,\n",
        "                    'Abstract_En': abstract,\n",
        "                    'Abstract_Source': 'PubMed',\n",
        "                    'URL': f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\",\n",
        "                    'PMID': pmid,\n",
        "                    'ID': f\"PMID:{pmid}\",\n",
        "                    'Citation_Count': get_citation_count(title, authors_str, doi),\n",
        "                    'Impact_Factor': get_journal_impact_factor(journal)\n",
        "                }\n",
        "                articles.append(article)\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PubMed XMLè§£æé”™è¯¯: {e}\")\n",
        "\n",
        "    return articles\n",
        "\n",
        "# ========== å…¶ä»–æ•°æ®æºæœç´¢ ==========\n",
        "def search_crossref():\n",
        "    \"\"\"æœç´¢CrossRef\"\"\"\n",
        "    print(\"ğŸ”¹ Searching CrossRef...\")\n",
        "    try:\n",
        "        query = build_custom_query(\"crossref\")\n",
        "        print(f\"   æŸ¥è¯¢: {query}\")\n",
        "\n",
        "        url = \"https://api.crossref.org/works\"\n",
        "        params = {\n",
        "            \"query\": query,\n",
        "            \"rows\": MAX_RESULTS_PER_SOURCE\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params, timeout=30)\n",
        "        if response.status_code != 200:\n",
        "            return []\n",
        "\n",
        "        data = response.json()\n",
        "        items = []\n",
        "\n",
        "        for item_data in data.get(\"message\", {}).get(\"items\", []):\n",
        "            authors = \", \".join([a.get(\"family\", \"\") for a in item_data.get(\"author\", [])]) if \"author\" in item_data else \"\"\n",
        "            year = \"\"\n",
        "            if item_data.get(\"created\"):\n",
        "                date_parts = item_data[\"created\"].get(\"date-parts\", [[None]])\n",
        "                if date_parts and date_parts[0]:\n",
        "                    year = str(date_parts[0][0]) if date_parts[0][0] else \"\"\n",
        "\n",
        "            journal = \"\"\n",
        "            container_title = item_data.get(\"container-title\", [\"\"])\n",
        "            if container_title:\n",
        "                journal = container_title[0]\n",
        "\n",
        "            doi = item_data.get(\"DOI\", \"\")\n",
        "            title = item_data.get(\"title\", [\"\"])[0] if item_data.get(\"title\") else \"No title\"\n",
        "            abs_text = clean_html(item_data.get(\"abstract\", \"\"))\n",
        "\n",
        "            item = {\n",
        "                \"ID\": f\"DOI:{doi}\" if doi else f\"CrossRef:{len(items)}\",\n",
        "                \"Title\": title,\n",
        "                \"Authors\": authors,\n",
        "                \"Year\": year,\n",
        "                \"DOI\": doi,\n",
        "                \"Link\": doi_to_link(doi),\n",
        "                \"Abstract_En\": abs_text,\n",
        "                \"Abstract_Source\": \"CrossRef\" if abs_text else \"No Abstract\",\n",
        "                \"Source\": \"CrossRef\",\n",
        "                \"Journal\": journal,\n",
        "                \"Citation_Count\": get_citation_count(title, authors, doi),\n",
        "                \"Impact_Factor\": get_journal_impact_factor(journal)\n",
        "            }\n",
        "            items.append(item)\n",
        "\n",
        "        print(f\"   âœ… æ‰¾åˆ° {len(items)} ä¸ªç»“æœ\")\n",
        "        return items\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ æœç´¢å¤±è´¥: {e}\")\n",
        "        return []\n",
        "\n",
        "def search_semantic_scholar():\n",
        "    \"\"\"æœç´¢Semantic Scholar\"\"\"\n",
        "    print(\"ğŸ”¹ Searching Semantic Scholar...\")\n",
        "    try:\n",
        "        query = build_custom_query(\"semantic\")\n",
        "        print(f\"   æŸ¥è¯¢: {query}\")\n",
        "\n",
        "        url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "        params = {\n",
        "            \"query\": query,\n",
        "            \"limit\": min(MAX_RESULTS_PER_SOURCE, 10),\n",
        "            \"fields\": \"title,abstract,authors,year,externalIds,url,venue,citationCount,paperId\"\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params, timeout=30)\n",
        "        if response.status_code != 200:\n",
        "            return []\n",
        "\n",
        "        data = response.json()\n",
        "        items = []\n",
        "\n",
        "        for paper in data.get(\"data\", []):\n",
        "            doi = paper.get(\"externalIds\", {}).get(\"DOI\", \"\")\n",
        "            authors = \", \".join([a[\"name\"] for a in paper.get(\"authors\", [])]) if paper.get(\"authors\") else \"\"\n",
        "\n",
        "            item = {\n",
        "                \"ID\": f\"SS:{paper.get('paperId', '')}\",\n",
        "                \"Title\": paper.get(\"title\", \"No title\"),\n",
        "                \"Authors\": authors,\n",
        "                \"Year\": str(paper.get(\"year\", \"\")),\n",
        "                \"DOI\": doi,\n",
        "                \"Link\": doi_to_link(doi) if doi else paper.get(\"url\", \"\"),\n",
        "                \"Abstract_En\": clean_html(paper.get(\"abstract\", \"\")),\n",
        "                \"Abstract_Source\": \"Semantic Scholar\",\n",
        "                \"Source\": \"Semantic Scholar\",\n",
        "                \"Journal\": paper.get(\"venue\", \"\"),\n",
        "                \"Citation_Count\": paper.get(\"citationCount\", 0),\n",
        "                \"Impact_Factor\": get_journal_impact_factor(paper.get(\"venue\", \"\"))\n",
        "            }\n",
        "            items.append(item)\n",
        "\n",
        "        print(f\"   âœ… æ‰¾åˆ° {len(items)} ä¸ªç»“æœ\")\n",
        "        return items\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ æœç´¢å¤±è´¥: {e}\")\n",
        "        return []\n",
        "\n",
        "# ========== ä¸»æœç´¢æµç¨‹ ==========\n",
        "def search_all_sources():\n",
        "    \"\"\"æœç´¢æ‰€æœ‰æ•°æ®æº\"\"\"\n",
        "    print(\"ğŸš€ å¼€å§‹å¤šæºæ–‡çŒ®æ”¶é›†\")\n",
        "    print(f\"ğŸ¯ æœç´¢é€»è¾‘: {SEARCH_LOGIC}\")\n",
        "    print(f\"ğŸ“… æ—¶é—´èŒƒå›´: {START_YEAR}-{END_YEAR}\")\n",
        "\n",
        "    all_items = []\n",
        "    search_functions = [\n",
        "        (\"PubMed\", search_pubmed),\n",
        "        (\"CrossRef\", search_crossref),\n",
        "        (\"Semantic Scholar\", search_semantic_scholar)\n",
        "    ]\n",
        "\n",
        "    for source_name, search_func in search_functions:\n",
        "        try:\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"ğŸ” æ­£åœ¨æœç´¢ {source_name}...\")\n",
        "            results = search_func()\n",
        "            all_items.extend(results)\n",
        "            print(f\"ğŸ“¥ ä» {source_name} æ·»åŠ äº† {len(results)} ä¸ªç»“æœ\")\n",
        "            time.sleep(1)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ {source_name} æœç´¢é”™è¯¯: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\nğŸ‰ å¤šæºæœç´¢å®Œæˆ! æ€»è®¡æ‰¾åˆ° {len(all_items)} ç¯‡æ–‡çŒ®\")\n",
        "    return all_items\n",
        "\n",
        "# ========== HTMLæŠ¥å‘Šç”ŸæˆåŠŸèƒ½ ==========\n",
        "def generate_enhanced_html_report_with_toc(final_data):\n",
        "    \"\"\"ç”Ÿæˆå¸¦ç›®å½•å¯¼èˆªçš„å¢å¼ºHTMLæŠ¥å‘Š\"\"\"\n",
        "    print(\"ğŸ“„ ç”Ÿæˆå¸¦ç›®å½•å¯¼èˆªçš„å¢å¼ºHTMLæŠ¥å‘Š...\")\n",
        "\n",
        "    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯\n",
        "    total_articles = len(final_data)\n",
        "    articles_with_abstract = len([item for item in final_data if item.get(\"Abstract_En\") and \"not available\" not in item.get(\"Abstract_En\", \"\").lower()])\n",
        "    articles_with_doi = len([item for item in final_data if item.get(\"DOI\")])\n",
        "\n",
        "    # æŒ‰å¹´ä»½ç»Ÿè®¡\n",
        "    year_stats = {}\n",
        "    for item in final_data:\n",
        "        year = item.get(\"Year\", \"Unknown\")\n",
        "        if year and year != \"Unknown\":\n",
        "            year_str = str(year).strip()\n",
        "            if year_str and year_str != \"Unknown\":\n",
        "                if year_str in year_stats:\n",
        "                    year_stats[year_str] += 1\n",
        "                else:\n",
        "                    year_stats[year_str] = 1\n",
        "\n",
        "    # æŒ‰æ•°æ®æºç»Ÿè®¡\n",
        "    source_stats = {}\n",
        "    for item in final_data:\n",
        "        source = item.get(\"Source\", \"Unknown\")\n",
        "        if source in source_stats:\n",
        "            source_stats[source] += 1\n",
        "        else:\n",
        "            source_stats[source] = 1\n",
        "\n",
        "    # ç”Ÿæˆå¹´ä»½ç»Ÿè®¡å›¾è¡¨HTML\n",
        "    year_chart_html = \"\"\n",
        "    if year_stats:\n",
        "        numeric_years = {}\n",
        "        for year, count in year_stats.items():\n",
        "            try:\n",
        "                year_int = int(year)\n",
        "                if START_YEAR <= year_int <= END_YEAR:\n",
        "                    numeric_years[year_int] = count\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        if numeric_years:\n",
        "            sorted_years = sorted(numeric_years.keys())\n",
        "            max_count = max(numeric_years.values()) if numeric_years else 1\n",
        "\n",
        "            for year in sorted_years:\n",
        "                count = numeric_years[year]\n",
        "                percentage = (count / max_count) * 80 if max_count > 0 else 0\n",
        "                year_chart_html += f\"\"\"\n",
        "                <div class=\"year-bar\">\n",
        "                    <div class=\"year-label\">{year}</div>\n",
        "                    <div class=\"bar-container\">\n",
        "                        <div class=\"bar-fill\" style=\"width: {percentage}%\"></div>\n",
        "                        <div class=\"bar-count\">{count}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "    # ç”Ÿæˆç›®å½•\n",
        "    toc_items = []\n",
        "    for i, article in enumerate(final_data, 1):\n",
        "        year = article.get(\"Year\", \"Unknown\")\n",
        "        journal = article.get(\"Journal\", \"\")[:30]\n",
        "\n",
        "        toc_item = f\"\"\"\n",
        "        <li class=\"toc-item\">\n",
        "            <a href=\"#article-{i}\" class=\"toc-link\">\n",
        "                <span class=\"toc-number\">{i}.</span>\n",
        "                <span class=\"toc-title\">{article[\"Title\"][:70]}...</span>\n",
        "            </a>\n",
        "            <div class=\"toc-meta\">\n",
        "                <span class=\"toc-year\">{year}</span>\n",
        "                <span class=\"toc-journal\">{journal}</span>\n",
        "            </div>\n",
        "        </li>\n",
        "        \"\"\"\n",
        "        toc_items.append(toc_item)\n",
        "\n",
        "    # ç”Ÿæˆå®Œæ•´çš„HTMLå†…å®¹\n",
        "    html_content = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html lang=\"zh-CN\">\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "        <title>å¤šæºæ–‡çŒ®æ£€ç´¢æŠ¥å‘Š - {', '.join(KEYWORDS)}</title>\n",
        "        <style>\n",
        "            :root {{\n",
        "                --primary-color: #2c3e50;\n",
        "                --secondary-color: #3498db;\n",
        "                --accent-color: #e74c3c;\n",
        "                --light-bg: #f8f9fa;\n",
        "                --border-color: #ddd;\n",
        "            }}\n",
        "\n",
        "            * {{\n",
        "                margin: 0;\n",
        "                padding: 0;\n",
        "                box-sizing: border-box;\n",
        "            }}\n",
        "\n",
        "            body {{\n",
        "                font-family: 'Microsoft YaHei', 'Segoe UI', Arial, sans-serif;\n",
        "                line-height: 1.6;\n",
        "                color: #333;\n",
        "                background: #f5f7fa;\n",
        "            }}\n",
        "\n",
        "            .container {{\n",
        "                display: flex;\n",
        "                min-height: 100vh;\n",
        "            }}\n",
        "\n",
        "            .sidebar {{\n",
        "                width: 350px;\n",
        "                background: var(--primary-color);\n",
        "                color: white;\n",
        "                padding: 20px;\n",
        "                position: fixed;\n",
        "                height: 100vh;\n",
        "                overflow-y: auto;\n",
        "                border-right: 3px solid var(--secondary-color);\n",
        "            }}\n",
        "\n",
        "            .sidebar-header {{\n",
        "                text-align: center;\n",
        "                margin-bottom: 25px;\n",
        "                padding-bottom: 15px;\n",
        "                border-bottom: 2px solid var(--secondary-color);\n",
        "            }}\n",
        "\n",
        "            .toc-list {{\n",
        "                list-style: none;\n",
        "                max-height: calc(100vh - 200px);\n",
        "                overflow-y: auto;\n",
        "            }}\n",
        "\n",
        "            .toc-item {{\n",
        "                margin-bottom: 12px;\n",
        "                padding: 10px;\n",
        "                border-radius: 8px;\n",
        "                transition: all 0.3s ease;\n",
        "                border-left: 3px solid transparent;\n",
        "            }}\n",
        "\n",
        "            .toc-item:hover {{\n",
        "                background: rgba(255,255,255,0.1);\n",
        "                border-left-color: var(--secondary-color);\n",
        "            }}\n",
        "\n",
        "            .toc-link {{\n",
        "                color: #ecf0f1;\n",
        "                text-decoration: none;\n",
        "                display: block;\n",
        "                font-weight: 500;\n",
        "            }}\n",
        "\n",
        "            .toc-number {{\n",
        "                color: var(--secondary-color);\n",
        "                font-weight: bold;\n",
        "                margin-right: 5px;\n",
        "            }}\n",
        "\n",
        "            .toc-title {{\n",
        "                font-size: 0.9em;\n",
        "                line-height: 1.4;\n",
        "            }}\n",
        "\n",
        "            .toc-meta {{\n",
        "                margin-top: 5px;\n",
        "                font-size: 0.75em;\n",
        "                color: #bdc3c7;\n",
        "                display: flex;\n",
        "                justify-content: space-between;\n",
        "            }}\n",
        "\n",
        "            .main-content {{\n",
        "                flex: 1;\n",
        "                padding: 30px;\n",
        "                margin-left: 350px;\n",
        "            }}\n",
        "\n",
        "            .header {{\n",
        "                text-align: center;\n",
        "                margin-bottom: 30px;\n",
        "                padding: 25px;\n",
        "                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                color: white;\n",
        "                border-radius: 15px;\n",
        "            }}\n",
        "\n",
        "            .search-info {{\n",
        "                background: var(--light-bg);\n",
        "                padding: 20px;\n",
        "                border-radius: 10px;\n",
        "                margin-bottom: 25px;\n",
        "                display: grid;\n",
        "                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
        "                gap: 15px;\n",
        "            }}\n",
        "\n",
        "            .info-item {{\n",
        "                text-align: center;\n",
        "            }}\n",
        "\n",
        "            .info-label {{\n",
        "                font-size: 0.9em;\n",
        "                color: #666;\n",
        "                margin-bottom: 5px;\n",
        "            }}\n",
        "\n",
        "            .info-value {{\n",
        "                font-size: 1.4em;\n",
        "                font-weight: bold;\n",
        "                color: var(--secondary-color);\n",
        "            }}\n",
        "\n",
        "            .year-stats {{\n",
        "                background: white;\n",
        "                padding: 20px;\n",
        "                border-radius: 10px;\n",
        "                margin-bottom: 25px;\n",
        "            }}\n",
        "\n",
        "            .year-bar {{\n",
        "                display: flex;\n",
        "                align-items: center;\n",
        "                margin-bottom: 10px;\n",
        "                gap: 10px;\n",
        "            }}\n",
        "\n",
        "            .bar-container {{\n",
        "                flex: 1;\n",
        "                background: #ecf0f1;\n",
        "                height: 25px;\n",
        "                border-radius: 12px;\n",
        "                position: relative;\n",
        "                overflow: hidden;\n",
        "            }}\n",
        "\n",
        "            .bar-fill {{\n",
        "                background: linear-gradient(90deg, #3498db, #2ecc71);\n",
        "                height: 100%;\n",
        "                border-radius: 12px;\n",
        "            }}\n",
        "\n",
        "            /* æ–‡ç« å¡ç‰‡æ ·å¼ */\n",
        "            .article {{\n",
        "                border: 1px solid var(--border-color);\n",
        "                border-radius: 12px;\n",
        "                padding: 25px;\n",
        "                margin-bottom: 25px;\n",
        "                background: white;\n",
        "                position: relative;\n",
        "            }}\n",
        "\n",
        "            .article-header {{\n",
        "                display: flex;\n",
        "                justify-content: space-between;\n",
        "                align-items: flex-start;\n",
        "                margin-bottom: 15px;\n",
        "            }}\n",
        "\n",
        "            .article-title {{\n",
        "                color: var(--primary-color);\n",
        "                font-size: 1.3em;\n",
        "                font-weight: bold;\n",
        "                margin-bottom: 10px;\n",
        "                flex: 1;\n",
        "                line-height: 1.4;\n",
        "            }}\n",
        "\n",
        "            .article-metrics {{\n",
        "                display: flex;\n",
        "                gap: 10px;\n",
        "                margin-left: 15px;\n",
        "                flex-wrap: wrap;\n",
        "                justify-content: flex-end;\n",
        "            }}\n",
        "\n",
        "            .metric {{\n",
        "                background: var(--light-bg);\n",
        "                padding: 5px 10px;\n",
        "                border-radius: 15px;\n",
        "                font-size: 0.8em;\n",
        "                display: flex;\n",
        "                align-items: center;\n",
        "                gap: 5px;\n",
        "                white-space: nowrap;\n",
        "            }}\n",
        "\n",
        "            .metric.citations {{\n",
        "                background: #ffeaa7;\n",
        "                color: #d35400;\n",
        "                font-weight: bold;\n",
        "            }}\n",
        "\n",
        "            .metric.impact {{\n",
        "                background: #a29bfe;\n",
        "                color: white;\n",
        "                font-weight: bold;\n",
        "            }}\n",
        "\n",
        "            .metric.year {{\n",
        "                background: #74b9ff;\n",
        "                color: white;\n",
        "                padding: 5px 10px;\n",
        "                border-radius: 15px;\n",
        "                font-size: 0.8em;\n",
        "                display: flex;\n",
        "                align-items: center;\n",
        "                gap: 5px;\n",
        "            }}\n",
        "\n",
        "            .article-meta {{\n",
        "                color: #666;\n",
        "                font-size: 0.95em;\n",
        "                margin-bottom: 15px;\n",
        "                line-height: 1.5;\n",
        "            }}\n",
        "\n",
        "            .doi-link {{\n",
        "                color: var(--secondary-color);\n",
        "                text-decoration: none;\n",
        "                font-weight: 500;\n",
        "            }}\n",
        "\n",
        "            .doi-link:hover {{\n",
        "                text-decoration: underline;\n",
        "            }}\n",
        "\n",
        "            .abstract-section {{\n",
        "                margin-top: 20px;\n",
        "            }}\n",
        "\n",
        "            .abstract-en {{\n",
        "                background: var(--light-bg);\n",
        "                padding: 18px;\n",
        "                border-radius: 8px;\n",
        "                margin-bottom: 12px;\n",
        "                line-height: 1.6;\n",
        "            }}\n",
        "\n",
        "            .abstract-zh {{\n",
        "                background: #e8f4fd;\n",
        "                padding: 18px;\n",
        "                border-radius: 8px;\n",
        "                border-left: 4px solid var(--secondary-color);\n",
        "                line-height: 1.6;\n",
        "            }}\n",
        "\n",
        "            .abstract-source {{\n",
        "                font-size: 0.8em;\n",
        "                color: #7f8c8d;\n",
        "                margin-top: 5px;\n",
        "                text-align: right;\n",
        "            }}\n",
        "\n",
        "            /* å“åº”å¼è®¾è®¡ */\n",
        "            @media (max-width: 768px) {{\n",
        "                .container {{\n",
        "                    flex-direction: column;\n",
        "                }}\n",
        "                .sidebar {{\n",
        "                    position: relative;\n",
        "                    width: 100%;\n",
        "                    height: auto;\n",
        "                }}\n",
        "                .main-content {{\n",
        "                    margin-left: 0;\n",
        "                }}\n",
        "                .article-header {{\n",
        "                    flex-direction: column;\n",
        "                }}\n",
        "                .article-metrics {{\n",
        "                    margin-left: 0;\n",
        "                    margin-top: 10px;\n",
        "                    justify-content: flex-start;\n",
        "                }}\n",
        "            }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"container\">\n",
        "            <div class=\"sidebar\">\n",
        "                <div class=\"sidebar-header\">\n",
        "                    <h2>ğŸ“‘ æ–‡çŒ®ç›®å½•</h2>\n",
        "                    <div>å…± {total_articles} ç¯‡æ–‡çŒ®</div>\n",
        "                </div>\n",
        "                <ul class=\"toc-list\">\n",
        "                    {''.join(toc_items)}\n",
        "                </ul>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"main-content\">\n",
        "                <div class=\"header\">\n",
        "                    <h1>ğŸ“š å¤šæºæ–‡çŒ®æ£€ç´¢æŠ¥å‘Š</h1>\n",
        "                    <p>æ£€ç´¢æ—¶é—´: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\n",
        "                </div>\n",
        "\n",
        "                <div class=\"search-info\">\n",
        "                    <div class=\"info-item\">\n",
        "                        <div class=\"info-label\">å…³é”®è¯</div>\n",
        "                        <div class=\"info-value\">{\", \".join(KEYWORDS)}</div>\n",
        "                    </div>\n",
        "                    <div class=\"info-item\">\n",
        "                        <div class=\"info-label\">æ—¶é—´èŒƒå›´</div>\n",
        "                        <div class=\"info-value\">{START_YEAR}-{END_YEAR}</div>\n",
        "                    </div>\n",
        "                    <div class=\"info-item\">\n",
        "                        <div class=\"info-label\">æ€»æ–‡çŒ®æ•°</div>\n",
        "                        <div class=\"info-value\">{total_articles}</div>\n",
        "                    </div>\n",
        "                    <div class=\"info-item\">\n",
        "                        <div class=\"info-label\">æœ‰æ‘˜è¦</div>\n",
        "                        <div class=\"info-value\">{articles_with_abstract}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "\n",
        "                <div class=\"year-stats\">\n",
        "                    <h3>ğŸ“Š æ–‡çŒ®å‘è¡¨å¹´ä»½åˆ†å¸ƒ</h3>\n",
        "                    {year_chart_html if year_chart_html else \"<p style='text-align: center; color: #666;'>æš‚æ— å¹´ä»½æ•°æ®</p>\"}\n",
        "                </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # æ–‡ç« å†…å®¹ - ä¿®å¤ï¼šæ·»åŠ å½±å“å› å­å’Œå¼•ç”¨æ¬¡æ•°æ˜¾ç¤º\n",
        "    for i, article in enumerate(final_data, 1):\n",
        "        doi_link = article.get('Link', '') if article.get('Link') else (f\"https://doi.org/{article['DOI']}\" if article.get('DOI') else \"\")\n",
        "        link_text = article.get('DOI', '') if article.get('DOI') else \"æŸ¥çœ‹åŸæ–‡\"\n",
        "\n",
        "        # æ„å»ºæŒ‡æ ‡æ ‡ç­¾\n",
        "        metrics_html = \"\"\n",
        "\n",
        "        # å¼•ç”¨æ¬¡æ•°\n",
        "        citation_count = article.get('Citation_Count', 0)\n",
        "        if citation_count > 0:\n",
        "            metrics_html += f'<div class=\"metric citations\">ğŸ“Š {citation_count} å¼•ç”¨</div>'\n",
        "\n",
        "        # å½±å“å› å­\n",
        "        impact_factor = article.get('Impact_Factor', 0)\n",
        "        if impact_factor and impact_factor > 0:\n",
        "            metrics_html += f'<div class=\"metric impact\">â­ IF: {impact_factor:.1f}</div>'\n",
        "\n",
        "        # å¹´ä»½\n",
        "        year = article.get('Year', 'Unknown')\n",
        "        if year and year != 'Unknown':\n",
        "            metrics_html += f'<div class=\"metric year\">ğŸ“… {year}</div>'\n",
        "\n",
        "        html_content += f\"\"\"\n",
        "                <div class=\"article\" id=\"article-{i}\">\n",
        "                    <div class=\"article-header\">\n",
        "                        <div class=\"article-title\">\n",
        "                            {i}. {article.get('Title', 'æ— æ ‡é¢˜')}\n",
        "                        </div>\n",
        "                        <div class=\"article-metrics\">\n",
        "                            {metrics_html}\n",
        "                        </div>\n",
        "                    </div>\n",
        "\n",
        "                    <div class=\"article-meta\">\n",
        "                        <strong>ğŸ‘¥ ä½œè€…:</strong> {article.get('Authors', 'æœªçŸ¥ä½œè€…')}<br>\n",
        "                        <strong>ğŸ“… å¹´ä»½:</strong> {article.get('Year', 'æœªçŸ¥å¹´ä»½')} |\n",
        "                        <strong>ğŸ“š æœŸåˆŠ:</strong> {article.get('Journal', 'æœªçŸ¥æœŸåˆŠ')}<br>\n",
        "                        <strong>ğŸ”— é“¾æ¥:</strong>\n",
        "                        <a href=\"{doi_link}\" class=\"doi-link\" target=\"_blank\">{link_text}</a>\n",
        "                        <span style=\"margin-left: 10px; color: #7f8c8d;\">æ¥æº: {article.get('Source', 'æœªçŸ¥')} | ID: {article.get('ID', 'æœªçŸ¥')}</span>\n",
        "                    </div>\n",
        "\n",
        "                    <div class=\"abstract-section\">\n",
        "                        <strong>ğŸ“„ è‹±æ–‡æ‘˜è¦:</strong>\n",
        "                        <div class=\"abstract-en\">\n",
        "                            {article.get('Abstract_En', 'æ— æ‘˜è¦')}\n",
        "                            <div class=\"abstract-source\">\n",
        "                                æ‘˜è¦æ¥æº: {article.get('Abstract_Source', 'æœªçŸ¥')}\n",
        "                            </div>\n",
        "                        </div>\n",
        "\n",
        "                        <strong>ğŸ“– ä¸­æ–‡æ‘˜è¦:</strong>\n",
        "                        <div class=\"abstract-zh\">\n",
        "                            {article.get('Abstract_Zh', 'æ— ä¸­æ–‡æ‘˜è¦')}\n",
        "                        </div>\n",
        "                    </div>\n",
        "                </div>\n",
        "        \"\"\"\n",
        "\n",
        "    html_content += \"\"\"\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <script>\n",
        "            // å¹³æ»‘æ»šåŠ¨\n",
        "            document.querySelectorAll('.toc-link').forEach(link => {\n",
        "                link.addEventListener('click', function(e) {\n",
        "                    e.preventDefault();\n",
        "                    const targetId = this.getAttribute('href');\n",
        "                    const targetElement = document.querySelector(targetId);\n",
        "                    if (targetElement) {\n",
        "                        targetElement.scrollIntoView({\n",
        "                            behavior: 'smooth',\n",
        "                            block: 'start'\n",
        "                        });\n",
        "                    }\n",
        "                });\n",
        "            });\n",
        "\n",
        "            // æ»šåŠ¨æ—¶é«˜äº®å½“å‰é˜…è¯»çš„ç« èŠ‚\n",
        "            window.addEventListener('scroll', function() {\n",
        "                const articles = document.querySelectorAll('.article');\n",
        "                const tocItems = document.querySelectorAll('.toc-item');\n",
        "\n",
        "                let current = '';\n",
        "                articles.forEach(article => {\n",
        "                    const articleTop = article.offsetTop;\n",
        "                    if (pageYOffset >= (articleTop - 200)) {\n",
        "                        current = article.getAttribute('id');\n",
        "                    }\n",
        "                });\n",
        "\n",
        "                tocItems.forEach(item => {\n",
        "                    item.classList.remove('active');\n",
        "                    const link = item.querySelector('.toc-link');\n",
        "                    if (link.getAttribute('href') === '#' + current) {\n",
        "                        item.classList.add('active');\n",
        "                    }\n",
        "                });\n",
        "            });\n",
        "        </script>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    return html_content\n",
        "\n",
        "# ========== ä¿®æ”¹ä¸»æ‰§è¡Œæµç¨‹ ==========\n",
        "def main():\n",
        "    \"\"\"ä¸»æ‰§è¡Œå‡½æ•°\"\"\"\n",
        "    print(\"ğŸ¯ å¼€å§‹æ‰§è¡Œå®Œæ•´æœç´¢æµç¨‹...\")\n",
        "\n",
        "    # é˜¶æ®µ1: å¤šæºæœç´¢\n",
        "    print(\"\\nğŸ“š é˜¶æ®µ1: å¤šæºæœç´¢\")\n",
        "    all_items = search_all_sources()\n",
        "\n",
        "    if not all_items:\n",
        "        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡ç« ã€‚è¯·æ£€æŸ¥æœç´¢è¯ã€‚\")\n",
        "        return []\n",
        "\n",
        "    # é˜¶æ®µ2: å»é‡\n",
        "    print(\"\\nğŸ”„ é˜¶æ®µ2: å»é‡\")\n",
        "    final_data = advanced_deduplication(all_items)\n",
        "    print(f\"âœ… å»é‡å®Œæˆ: {len(final_data)} ä¸ªå”¯ä¸€é¡¹ç›®\")\n",
        "\n",
        "    # é˜¶æ®µ3: æ‘˜è¦è¡¥å…¨å’Œç¿»è¯‘\n",
        "    print(\"\\nğŸŒ é˜¶æ®µ3: æ‘˜è¦è¡¥å…¨å’Œç¿»è¯‘\")\n",
        "    final_data = batch_force_get_abstracts(final_data)\n",
        "\n",
        "    # é˜¶æ®µ4: å¢å¼ºå…ƒæ•°æ®ï¼ˆæ–°å¢ï¼‰\n",
        "    print(\"\\nğŸ”§ é˜¶æ®µ4: å¢å¼ºæ–‡çŒ®å…ƒæ•°æ®\")\n",
        "    final_data = batch_enhance_metadata(final_data)\n",
        "\n",
        "    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆæ›´æ–°ç»Ÿè®¡å†…å®¹ï¼‰\n",
        "    print(f\"\\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:\")\n",
        "    print(f\"  æ€»å”¯ä¸€æ–‡ç« æ•°: {len(final_data)}\")\n",
        "    print(f\"  æœ‰DOIçš„æ–‡ç« : {len([a for a in final_data if a['DOI']])}\")\n",
        "    print(f\"  æœ‰æ‘˜è¦çš„æ–‡ç« : {len([a for a in final_data if a['Abstract_En'] != 'Abstract not available'])}\")\n",
        "    print(f\"  æœ‰å½±å“å› å­çš„æ–‡ç« : {len([a for a in final_data if a.get('Impact_Factor', 0) > 0])}\")\n",
        "    print(f\"  æœ‰å¼•ç”¨æ¬¡æ•°çš„æ–‡ç« : {len([a for a in final_data if a.get('Citation_Count', 0) > 0])}\")\n",
        "\n",
        "    # æ–°å¢ï¼šæ˜¾ç¤ºæ•°æ®æ¥æºç»Ÿè®¡\n",
        "    if_sources = {}\n",
        "    citation_sources = {}\n",
        "    for item in final_data:\n",
        "        if_source = item.get('Impact_Factor_Source', 'Unknown')\n",
        "        citation_source = item.get('Citation_Source', 'Unknown')\n",
        "        if_sources[if_source] = if_sources.get(if_source, 0) + 1\n",
        "        citation_sources[citation_source] = citation_sources.get(citation_source, 0) + 1\n",
        "\n",
        "    print(f\"  å½±å“å› å­æ¥æºåˆ†å¸ƒ: {if_sources}\")\n",
        "    print(f\"  å¼•ç”¨æ¬¡æ•°æ¥æºåˆ†å¸ƒ: {citation_sources}\")\n",
        "\n",
        "    # ä¿å­˜ä¸ºCSVï¼ˆç¡®ä¿åŒ…å«æ–°å­—æ®µï¼‰\n",
        "    csv_filename = f\"{DATE_PREFIX}_literature_results.csv\"\n",
        "\n",
        "    # ç¡®ä¿æ‰€æœ‰æ–‡ç« éƒ½æœ‰æ–°å­—æ®µ\n",
        "    for item in final_data:\n",
        "        item.setdefault('Impact_Factor_Source', 'Not Enhanced')\n",
        "        item.setdefault('Citation_Source', 'Not Enhanced')\n",
        "\n",
        "    df = pd.DataFrame(final_data)\n",
        "\n",
        "    # ä¼˜åŒ–åˆ—çš„é¡ºåº\n",
        "    preferred_order = ['Source', 'Title', 'Authors', 'Year', 'Journal',\n",
        "                      'Impact_Factor', 'Impact_Factor_Source', 'Citation_Count', 'Citation_Source',\n",
        "                      'DOI', 'URL', 'Abstract_En', 'Abstract_Zh', 'Abstract_Source', 'ID']\n",
        "\n",
        "    # é‡æ–°æ’åˆ—åˆ—\n",
        "    existing_columns = [col for col in preferred_order if col in df.columns]\n",
        "    other_columns = [col for col in df.columns if col not in preferred_order]\n",
        "    df = df[existing_columns + other_columns]\n",
        "\n",
        "    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
        "    print(f\"ğŸ’¾ æ•°æ®å·²ä¿å­˜ä¸º: {csv_filename}\")\n",
        "\n",
        "    # ç”ŸæˆHTMLæŠ¥å‘Š\n",
        "    print(\"\\nğŸ“„ ç”ŸæˆHTMLæŠ¥å‘Š...\")\n",
        "    html_report = generate_enhanced_html_report_with_toc(final_data)\n",
        "    html_filename = f\"{DATE_PREFIX}_Literature_Report.html\"\n",
        "\n",
        "    with open(html_filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(html_report)\n",
        "\n",
        "    print(f\"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_filename}\")\n",
        "    print(f\"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(html_filename) / 1024:.1f} KB\")\n",
        "\n",
        "    # æä¾›ä¸‹è½½\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(html_filename)\n",
        "        #files.download(csv_filename)  # åŒæ—¶ä¸‹è½½CSVæ–‡ä»¶\n",
        "        print(\"â¬‡ï¸ è‡ªåŠ¨ä¸‹è½½å·²å¯åŠ¨...\")\n",
        "    except:\n",
        "        # å¦‚æœåœ¨æœ¬åœ°ç¯å¢ƒæˆ–å…¶ä»–ç¯å¢ƒ\n",
        "        with open(html_filename, 'rb') as f:\n",
        "            html_b64 = base64.b64encode(f.read()).decode()\n",
        "\n",
        "        with open(csv_filename, 'rb') as f:\n",
        "            csv_b64 = base64.b64encode(f.read()).decode()\n",
        "\n",
        "        display(HTML(f'''\n",
        "        <div style=\"display: flex; gap: 10px; margin: 10px 0;\">\n",
        "            <a href=\"data:text/html;base64,{html_b64}\" download=\"{html_filename}\">\n",
        "                <button style=\"font-size:16px; padding:10px 20px; background: #4CAF50; color: white; border: none; border-radius: 5px;\">\n",
        "                    ğŸ“„ ä¸‹è½½HTMLæŠ¥å‘Š\n",
        "                </button>\n",
        "            </a>\n",
        "            <a href=\"data:text/csv;base64,{csv_b64}\" download=\"{csv_filename}\">\n",
        "                <button style=\"font-size:16px; padding:10px 20px; background: #2196F3; color: white; border: none; border-radius: 5px;\">\n",
        "                    ğŸ“Š ä¸‹è½½CSVæ•°æ®\n",
        "                </button>\n",
        "            </a>\n",
        "        </div>\n",
        "        '''))\n",
        "\n",
        "    return final_data\n",
        "\n",
        "# ========== æ‰§è¡Œä¸»ç¨‹åº ==========\n",
        "if __name__ == \"__main__\":\n",
        "    final_data = main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ–°æ®µè½"
      ],
      "metadata": {
        "id": "3-YVXK2krSJx"
      }
    }
  ]
}